{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to read CONG data and save grasps, voxel grids and respective constrained masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model input - voxel grid (sdf + mask), grasp, scaling parameter\n",
    "\n",
    "For visualization - mesh, query points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import trimesh\n",
    "import trimesh.path\n",
    "import trimesh.transformations as tra\n",
    "import numpy as np\n",
    "# from acronym_tools import load_mesh, load_grasps, create_gripper_marker\n",
    "\n",
    "import os, json\n",
    "import trimesh\n",
    "import mesh2sdf\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "def makedirs(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "def create_voxel_grid(mesh, n=32):\n",
    "    \"\"\"\n",
    "    Uses the the mesh2sdf library to convert the mesh into a (n x n x n) voxel grid\n",
    "    The values within the grid are sdf (signed distance function) values\n",
    "    Input - \n",
    "        1. mesh_path --> Path to mesh file (.obj file)\n",
    "        2. n --> size of voxel grid\n",
    "    Output - \n",
    "        1. mesh --> mesh object after loading, normalizing and fixing mesh\n",
    "        2. sdf --> (n x n x n) numpy array \n",
    "    \"\"\"\n",
    "\n",
    "    # try:\n",
    "    mesh_scale = 0.8\n",
    "    size = n\n",
    "    level = 2 / size\n",
    "\n",
    "    # normalize mesh\n",
    "    vertices = mesh.vertices\n",
    "    bbmin = vertices.min(0)\n",
    "    bbmax = vertices.max(0)\n",
    "    center = (bbmin + bbmax) * 0.5\n",
    "    scale = 2.0 * mesh_scale / (bbmax - bbmin).max()\n",
    "    vertices = (vertices - center) * scale\n",
    "    # mesh_scaled = mesh.apply_scale(scale)\n",
    "\n",
    "    sdf = mesh2sdf.compute(\n",
    "        vertices, mesh.faces, size, fix=True, level=level, return_mesh=False)\n",
    "\n",
    "    mesh.vertices = vertices\n",
    "    return sdf, scale, center, mesh\n",
    "\n",
    "def point_to_voxel(point, grid_size):\n",
    "    \"\"\"Converts a point in the range [-1, 1] to voxel grid coordinates.\"\"\"\n",
    "    return np.clip(((point + 1) / 2) * (grid_size - 1), 0, grid_size - 1).astype(int)\n",
    "\n",
    "def update_mask(mask, points):\n",
    "    \"\"\"Updates the mask for each point in the list of points.\"\"\"\n",
    "    grid_size = mask.shape[0]  # Assuming the mask is a cubic grid\n",
    "    for point in points:\n",
    "        voxel = point_to_voxel(point, grid_size)\n",
    "        mask[voxel[0], voxel[1], voxel[2]] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "def center_grasps(grasps, center):\n",
    "    translation_T = np.zeros_like(np.eye(4))\n",
    "    translation_T[0][3] = -center[0]\n",
    "    translation_T[1][3] = -center[1]\n",
    "    translation_T[2][3] = -center[2]\n",
    "    g = grasps + translation_T\n",
    "    return g\n",
    "\n",
    "def get_n_query_points_and_grasps(data, T, center_scale, norm_scale, grasp_success_idxs, n=4):\n",
    "    count_succ = 0\n",
    "\n",
    "    num_pc = len(data['rendering/point_clouds'])\n",
    "\n",
    "    rand_pc_ix = np.random.choice(num_pc, size=min(n*4, num_pc), replace=False)\n",
    "\n",
    "    output = []\n",
    "    for pc_ix in rand_pc_ix:\n",
    "        obj = {}\n",
    "\n",
    "        pc = data['rendering/point_clouds'][pc_ix]\n",
    "\n",
    "        grasp_ix = data['query_points/grasp_indices_for_each_point_with_grasp_on_each_rendered_point_cloud'][pc_ix]\n",
    "        qp_ixes = data['query_points/points_with_grasps_on_each_rendered_point_cloud'][pc_ix]\n",
    "\n",
    "        cam_pose = data['rendering/camera_poses'][pc_ix]\n",
    "        if(len(qp_ixes) > 0):\n",
    "            # Randomly picking one set of query points\n",
    "            k = np.random.randint(0, len(qp_ixes)-1)\n",
    "            qp_ixes_rand = qp_ixes[k]\n",
    "            grasp_ix_rand = grasp_ix[k]\n",
    "            intersection_ix = np.intersect1d(grasp_ix_rand, grasp_success_idxs)\n",
    "\n",
    "            cam_pose_inv = np.linalg.inv(cam_pose)\n",
    "\n",
    "            query_point_arr = pc[qp_ixes_rand]\n",
    "            query_point_arr_added_dim = np.concatenate([query_point_arr, np.ones_like(query_point_arr[:, :1])], axis=1)\n",
    "            query_point_arr_t = (cam_pose_inv @ query_point_arr_added_dim.T).T\n",
    "            new_qp = query_point_arr_t[:,:3]\n",
    "            \n",
    "            # Now, we have correct query points (after applying camera pose inverse)\n",
    "\n",
    "            if(new_qp.shape[0] > 10):\n",
    "                count_succ += 1\n",
    "                if(count_succ > n):\n",
    "                    return output\n",
    "                new_qp_norm = (new_qp - center_scale) * norm_scale\n",
    "                mask = np.zeros((32, 32, 32))\n",
    "                mask = update_mask(mask, new_qp_norm)\n",
    "\n",
    "                obj['mask'] = mask\n",
    "                obj['query_points_normalized'] = new_qp_norm\n",
    "                # We center the grasps but we don't scale them, instead we will save this scale value and provide it as a input to the model\n",
    "                obj['constrained_grasps'] = center_grasps(T[intersection_ix], center_scale)\n",
    "                output.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7896\n"
     ]
    }
   ],
   "source": [
    "cong_dir = \"/home/username/data/cong\"\n",
    "cong_files = os.listdir(cong_dir)\n",
    "\n",
    "cong_files = [os.path.join(cong_dir, i) for i in cong_files]\n",
    "print(len(cong_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_output_dirname = \"/home/username/data/constrained/constrain_masks\"\n",
    "grasps_output_dirname = \"/home/username/data/constrained/grasps\"\n",
    "voxels_output_dirname = \"/home/username/data/constrained/voxel_grids\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single processing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cong_data_prepare(cong_path):\n",
    "\n",
    "    cong_fname = cong_path\n",
    "\n",
    "    mesh_root = \"/home/username/data/meshes\"\n",
    "    obj_type = os.path.basename(cong_fname).split(\"_\")[1]\n",
    "\n",
    "    # Read cong file\n",
    "    with open(cong_fname, 'rb') as f:\n",
    "        cong_data = pickle.load(f)\n",
    "\n",
    "    # Get grasps and success from cong data (same as acronym)\n",
    "    T = cong_data['grasps/transformations']\n",
    "    success = cong_data['grasps/successes']\n",
    "\n",
    "    mesh_scale = cong_data['mesh/scale'] # Scale from cong data (same as acronym)\n",
    "\n",
    "    # Loading and applying initial scale to mesh\n",
    "    mesh_fname = os.path.join(os.path.join(mesh_root, obj_type), os.path.basename(cong_data['mesh/file']))\n",
    "    mesh = trimesh.load(mesh_fname, force='mesh')\n",
    "    mesh = mesh.apply_scale(mesh_scale)\n",
    "\n",
    "    # Getting indices for all successful grasps\n",
    "    good_idxs = np.argwhere(success==1)[:,0]\n",
    "\n",
    "    # Normalizing mesh between -1 and 1, creating voxel grid\n",
    "    sdf, norm_scale, center_scale, mesh = create_voxel_grid(mesh, n=32)\n",
    "\n",
    "    num_pc = len(cong_data['rendering/point_clouds'])\n",
    "    # num_pc\n",
    "    rand_pc_ix = np.random.choice(num_pc, size=num_pc, replace=False)\n",
    "    rand_pc_ix\n",
    "\n",
    "    output = []\n",
    "    for pc_ix in rand_pc_ix:\n",
    "        obj = {}\n",
    "\n",
    "        pc = cong_data['rendering/point_clouds'][pc_ix]\n",
    "        grasp_ix = cong_data['query_points/grasp_indices_for_each_point_with_grasp_on_each_rendered_point_cloud'][pc_ix]\n",
    "        qp_ixes = cong_data['query_points/points_with_grasps_on_each_rendered_point_cloud'][pc_ix]\n",
    "        cam_pose = cong_data['rendering/camera_poses'][pc_ix]\n",
    "\n",
    "        if(len(qp_ixes) > 1):\n",
    "            # Randomly picking one set of query points\n",
    "            k = np.random.randint(0, len(qp_ixes)-1)\n",
    "            qp_ixes_rand = qp_ixes[k]\n",
    "            grasp_ix_rand = grasp_ix[k]\n",
    "            intersection_ix = np.intersect1d(grasp_ix_rand, good_idxs)\n",
    "\n",
    "            cam_pose_inv = np.linalg.inv(cam_pose)\n",
    "\n",
    "            query_point_arr = pc[qp_ixes_rand]\n",
    "            query_point_arr_added_dim = np.concatenate([query_point_arr, np.ones_like(query_point_arr[:, :1])], axis=1)\n",
    "            query_point_arr_t = (cam_pose_inv @ query_point_arr_added_dim.T).T\n",
    "            new_qp = query_point_arr_t[:,:3]\n",
    "            \n",
    "            # Now, we have correct query points (after applying camera pose inverse)\n",
    "\n",
    "            if(new_qp.shape[0] > 10):\n",
    "                if(len(output) > 1):\n",
    "                    break;\n",
    "                new_qp_norm = (new_qp - center_scale) * norm_scale\n",
    "                mask = np.zeros((32, 32, 32))\n",
    "                mask = update_mask(mask, new_qp_norm)\n",
    "\n",
    "                obj['mask'] = mask\n",
    "                # obj['query_points_normalized'] = new_qp_norm\n",
    "                obj['cam_pose'] = cam_pose\n",
    "                obj['cam_pose_inv'] = cam_pose_inv\n",
    "                # We center the grasps but we don't scale them, instead we will save this scale value and provide it as a input to the model\n",
    "                obj['constrained_grasps'] = center_grasps(T[intersection_ix], center_scale)\n",
    "                obj['new_qp'] = new_qp\n",
    "                output.append(obj)\n",
    "        # break;\n",
    "    try:\n",
    "        f = output[0]\n",
    "\n",
    "        temp = os.path.basename(cong_fname)[12:]\n",
    "        mask_output_fname = os.path.join(masks_output_dirname, os.path.splitext(temp)[0]+\".npz\")\n",
    "        np.savez_compressed(mask_output_fname, f['mask'])\n",
    "\n",
    "        voxel_grid_output_fname = os.path.join(voxels_output_dirname, os.path.splitext(temp)[0]+\".npz\")\n",
    "        np.savez_compressed(voxel_grid_output_fname, sdf)\n",
    "\n",
    "        grasp_output_fname = os.path.join(grasps_output_dirname, os.path.splitext(temp)[0]+\".h5\")\n",
    "\n",
    "        with h5py.File(grasp_output_fname, 'w') as new_data:\n",
    "            new_data.create_dataset(\"grasps/transforms\", data=f['constrained_grasps'])\n",
    "            new_data.create_dataset(\"object/file\", data=mesh_fname)\n",
    "            new_data.create_dataset(\"object/scale\", data=mesh_scale)\n",
    "            new_data.create_dataset(\"object/norm_scale\", data=norm_scale)\n",
    "            new_data.create_dataset(\"object/center_scale\", data=center_scale)\n",
    "            # These query points are already inverted by cam_pose_inv\n",
    "            new_data.create_dataset(\"object/query_points\", data=f['new_qp'])\n",
    "            new_data.create_dataset(\"camera_pose\", data=f['cam_pose'])\n",
    "            new_data.create_dataset(\"camera_pose_inv\", data=f['cam_pose_inv'])\n",
    "    except Exception as e:\n",
    "        return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "failed_counts = 0\n",
    "for i in tqdm(range(len(cong_files))):\n",
    "    # print(i)\n",
    "    s = cong_data_prepare(cong_files[i])\n",
    "    failed_counts += s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiprocessing setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trimesh/grouping.py:99: RuntimeWarning: invalid value encountered in cast\n",
      "  stacked = np.column_stack(stacked).round().astype(np.int64)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "        results = pool.map(cong_data_prepare, cong_files)\n",
    "\n",
    "# voxel_grid_maker(grasp_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new masks with l2 distance values instead of boolean 1s and 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7610"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grasps_output_dirname = \"/home/username/data/constrained/grasps\"\n",
    "grasp_files = [os.path.join(grasps_output_dirname, i) for i in os.listdir(grasps_output_dirname)]\n",
    "len(grasp_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.673825982930406, array([-4.65041885e-06,  2.13333187e-05,  1.19870689e-01]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grasp_fname = grasp_files[0]\n",
    "with h5py.File(grasp_fname, 'r') as data:\n",
    "    mesh_fname = data[\"object/file\"][()].decode('utf-8')\n",
    "    # mesh_type = mesh_fname.split('/')[1]\n",
    "    # mesh_id = mesh_fname.split('/')[-1].split('.')[0]\n",
    "    mesh_scale = data[\"object/scale\"][()]\n",
    "    mesh_norm_scale = data[\"object/norm_scale\"][()]\n",
    "\n",
    "    g = data['grasps/transforms'][()]\n",
    "    mesh_center_scale = data[\"object/center_scale\"][()]\n",
    "    qp_unscaled = data['object/query_points'][()]\n",
    "    \n",
    "mesh_norm_scale, mesh_center_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.37445774, 1.3523952 , 1.32976944, ..., 1.53247937,\n",
       "         1.56700394, 1.60296197],\n",
       "        [1.33886927, 1.31621033, 1.29326455, ..., 1.4991519 ,\n",
       "         1.53414744, 1.57085776],\n",
       "        [1.30550083, 1.28225237, 1.25900926, ..., 1.4677803 ,\n",
       "         1.50334297, 1.5407874 ],\n",
       "        ...,\n",
       "        [1.30271986, 1.29065786, 1.28173361, ..., 1.45826005,\n",
       "         1.48890866, 1.52167681],\n",
       "        [1.33700505, 1.32525514, 1.31656543, ..., 1.49167831,\n",
       "         1.52165398, 1.55373169],\n",
       "        [1.37346666, 1.36203133, 1.35357773, ..., 1.52709223,\n",
       "         1.55638599, 1.58776215]],\n",
       "\n",
       "       [[1.32750268, 1.30464635, 1.28271254, ..., 1.49044872,\n",
       "         1.52548303, 1.56239694],\n",
       "        [1.29062009, 1.26709863, 1.24482847, ..., 1.45586553,\n",
       "         1.49171227, 1.52944148],\n",
       "        [1.25597043, 1.2317875 , 1.20920181, ..., 1.42336789,\n",
       "         1.46001274, 1.49854027],\n",
       "        ...,\n",
       "        [1.24957629, 1.23699619, 1.22768193, ..., 1.41159684,\n",
       "         1.44323674, 1.47701848],\n",
       "        [1.28527988, 1.27305265, 1.26400411, ..., 1.44609387,\n",
       "         1.47699496, 1.51002167],\n",
       "        [1.32316761, 1.31129371, 1.30251086, ..., 1.48259703,\n",
       "         1.51275266, 1.54501519]],\n",
       "\n",
       "       [[1.28207541, 1.25839424, 1.23723112, ..., 1.44960656,\n",
       "         1.48560434, 1.52348482],\n",
       "        [1.24384653, 1.21942319, 1.19790955, ..., 1.41402483,\n",
       "         1.45090568, 1.48966876],\n",
       "        [1.20785583, 1.18268948, 1.16056787, ..., 1.38054262,\n",
       "         1.4182944 , 1.4579248 ],\n",
       "        ...,\n",
       "        [1.19755059, 1.18441804, 1.17468695, ..., 1.36638705,\n",
       "         1.39904976, 1.43387291],\n",
       "        [1.23475945, 1.22202683, 1.21259759, ..., 1.40199693,\n",
       "         1.43384869, 1.46784651],\n",
       "        [1.27415033, 1.26181525, 1.25268554, ..., 1.43961866,\n",
       "         1.47065582, 1.50382175]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.19459309, 1.17516152, 1.15740266, ..., 1.37113976,\n",
       "         1.40689771, 1.44404571],\n",
       "        [1.1486164 , 1.12839336, 1.11107364, ..., 1.32983837,\n",
       "         1.36603524, 1.40426462],\n",
       "        [1.10449594, 1.08344968, 1.0658986 , ..., 1.28976194,\n",
       "         1.3270524 , 1.36637291],\n",
       "        ...,\n",
       "        [1.04918232, 1.03484072, 1.02436895, ..., 1.25115582,\n",
       "         1.28496098, 1.32105383],\n",
       "        [1.09102818, 1.07724383, 1.06718822, ..., 1.29203448,\n",
       "         1.32479694, 1.35983287],\n",
       "        [1.13500049, 1.1217566 , 1.11210355, ..., 1.33478087,\n",
       "         1.36651887, 1.40051145]],\n",
       "\n",
       "       [[1.23474054, 1.21595071, 1.19908022, ..., 1.40704256,\n",
       "         1.44130182, 1.47758512],\n",
       "        [1.19031558, 1.17081301, 1.154425  , ..., 1.36618442,\n",
       "         1.40144285, 1.43873171],\n",
       "        [1.14779912, 1.12756142, 1.11070759, ..., 1.32720596,\n",
       "         1.36347272, 1.40177199],\n",
       "        ...,\n",
       "        [1.09437865, 1.08005238, 1.0694327 , ..., 1.29102983,\n",
       "         1.32381715, 1.35887834],\n",
       "        [1.13748814, 1.12427356, 1.1146423 , ..., 1.33068412,\n",
       "         1.36251755, 1.39660752],\n",
       "        [1.17973   , 1.16699385, 1.15771804, ..., 1.37222706,\n",
       "         1.40311829, 1.43624491]],\n",
       "\n",
       "       [[1.27688699, 1.25872647, 1.24271094, ..., 1.44432794,\n",
       "         1.47772304, 1.51313326],\n",
       "        [1.2339803 , 1.21517872, 1.19955655, ..., 1.40455485,\n",
       "         1.43887335, 1.47521638],\n",
       "        [1.19302097, 1.17356336, 1.15737961, ..., 1.36667118,\n",
       "         1.40191737, 1.43919393],\n",
       "        ...,\n",
       "        [1.13990224, 1.12615524, 1.11597437, ..., 1.33283525,\n",
       "         1.3646185 , 1.39865726],\n",
       "        [1.18293583, 1.1696947 , 1.15989606, ..., 1.37128116,\n",
       "         1.40219323, 1.4353412 ],\n",
       "        [1.22622359, 1.21397532, 1.2050612 , ..., 1.41162987,\n",
       "         1.44167706, 1.47393732]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_coordinate_grid(grid_size):\n",
    "    \"\"\"Create a 3D grid of voxel center coordinates.\"\"\"\n",
    "    # Generate a linear space from -1 to 1 for each dimension\n",
    "    lin = np.linspace(-1, 1, grid_size)\n",
    "    # Create a meshgrid for the 3D space\n",
    "    x, y, z = np.meshgrid(lin, lin, lin, indexing='ij')\n",
    "    # Stack the grids to a (grid_size, grid_size, grid_size, 3) array\n",
    "    return np.stack((x, y, z), axis=-1)\n",
    "\n",
    "def update_distance_mask(grid_size, points):\n",
    "    \"\"\"Update the mask with the closest distance to any of the points.\"\"\"\n",
    "    coordinate_grid = create_coordinate_grid(grid_size)\n",
    "    \n",
    "    mask = np.zeros((grid_size, grid_size, grid_size))\n",
    "    mask.fill(np.inf)\n",
    "\n",
    "    for point in points:\n",
    "        distances = np.linalg.norm(coordinate_grid - point, axis=-1)\n",
    "        np.minimum(mask, distances, out=mask)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Example\n",
    "grid_size = 32 \n",
    "points = (qp_unscaled - mesh_center_scale) * mesh_norm_scale\n",
    "mask = update_distance_mask(grid_size, points)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7610/7610 [1:03:28<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "dist_mask_output_dirname = \"/home/username/data/constrained/constrain_masks_distance\"\n",
    "\n",
    "# For all grasps\n",
    "for i in tqdm(range(len(grasp_files))):\n",
    "    grasp_fname = grasp_files[i]\n",
    "    temp = os.path.basename(grasp_fname)\n",
    "    with h5py.File(grasp_fname, 'r') as data:\n",
    "        mesh_fname = data[\"object/file\"][()].decode('utf-8')\n",
    "        # mesh_type = mesh_fname.split('/')[1]\n",
    "        # mesh_id = mesh_fname.split('/')[-1].split('.')[0]\n",
    "        mesh_scale = data[\"object/scale\"][()]\n",
    "        mesh_norm_scale = data[\"object/norm_scale\"][()]\n",
    "\n",
    "        g = data['grasps/transforms'][()]\n",
    "        mesh_center_scale = data[\"object/center_scale\"][()]\n",
    "        qp_unscaled = data['object/query_points'][()]\n",
    "    \n",
    "    grid_size = 32\n",
    "    points = (qp_unscaled - mesh_center_scale) * mesh_norm_scale\n",
    "    mask = update_distance_mask(grid_size, points)\n",
    "    # print(mask.shape)\n",
    "\n",
    "    dist_mask_output_fname = os.path.join(dist_mask_output_dirname, os.path.splitext(temp)[0]+\".npz\")\n",
    "    np.savez_compressed(dist_mask_output_fname, mask)\n",
    "    # break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if everything is running correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_output_dirname = \"/home/username/data/constrained/constrain_masks\"\n",
    "grasps_output_dirname = \"/home/username/data/constrained/grasps\"\n",
    "voxels_output_dirname = \"/home/username/data/constrained/voxel_grids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7610, 7610, 7610)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "voxels = os.listdir(voxels_output_dirname)\n",
    "grasps = os.listdir(grasps_output_dirname)\n",
    "masks = os.listdir(masks_output_dirname)\n",
    "\n",
    "len(voxels), len(grasps), len(masks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
